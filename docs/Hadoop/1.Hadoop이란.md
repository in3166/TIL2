  
 - DBMS 한계: 매우 큰 파일 처리 한계

# Haddop

- 대용량 데이터 분산 처리
- 자바 기반 오픈소스 프레임워크
- 대용량 자료를 처리할 수 있는 컴퓨터 클러스터에서 동작하는 분산 응용 프로그램을 지원하는 오픈소스 자바 프레임워크


- 분산시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 맵리듀스를 이용해 데이터 처리
 
  - 분산처리 (MapReduce): 각 서버에서 데이터를 분산 처리하는 분산 병렬 처리를 위한 분석시스템

## 분산 파일 시스템
- 물리적 다른 컴퓨터끼리 네트워크 연결, 사용자에게 동일하게 보이는 파일 접근 공간 제공하는 시스템
- 블레이드(Blade) 서버: 프로세서가 장착된 회로판, 기억장치, 선반에 장탁된 네트워크 접속부로 구성된 아주 얇은 컴퓨터
- 클라우드 데이터 센터
  - 서버 컴퓨터와 네트워크 회선 등을 제공하는 건물이나 시설
  - 컴퓨터 클러스터(cluster): 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터 집합
  
 ## HDFS (매우 큰 데이터 저장)
  - Java로 작성된 Google GFS 기반 파일 시스템
  - 분산저장 (HDFS: Hadoop Distributed File System): 빅데이터 파일을 여러 대의 서버에 분산 저장하기 위한 파일시스템
  - 클러스터에서 실행되는 매우 큰 파일 처리하도록 설계된 파일시스템
  
  - Master-Slave 구조
    - Master는 슬레이브 노드 사이의 저장 공간 분할, 데이터 저장 위치 관리
    - NameNode: 어떤 데이터노드가 각 파일 블록을 관리하는지 등과 같은 파일시스템 메타데이터를 메모리 보관
    - DataNode: 파일 읽기 및 쓰기 파이프라인 위해 서로 통신
  
  - 파일은 블록 구성, 여러번 복제. 즉, 파일의 블록별 동일한 복사본 여러 개 존재
  - 한 번 쓰고 여러 번 읽는 것이 목적
  - 저사양의 서버를 이용해 스토리지 구성 가능
  - 견고성: 장애 발생해도 데이터 잃지 않음, 확장성: 하드웨어 추가 성능 향상, 데이터분할 등 이점

  - 자바 기반의 파일 시스템
    - JVM (Java Virtual Machine)에서 동작
    - Java가 설치되어 있어야 함.
    
   - 하트비트(heartbeat)
     - 데이터노드는 네임노드에 하트비트를 3초마다 전송
     - 디스크 가용 공간 정보, 데이터이동, 적재량 등의 정보 가짐
     - 핸드셰이킹에 사용, 10초 이상 못받으면 사용하지 못한다고 인식
     
  ** 메타데이터: 데이터에 대한 데이터로 파일 블럭 정보(데이터가 어떤 컴퓨터에 있는지)에 대한 데이터
  <br/><br/>
  ### HDFS 파일 저장 방식
  - 파일은 블록단위로 분할(64mb or 128mb)
  - 데이터가 로드 될 때 여러 머신에 분산 저장
    - 같은 파일의 다른 블록들은 서로 다른 머신에 저장 -> 효율적 MapReduce 가능
  - 블록들은 여러 머신에 복제되어 데이터 노드에 저장
    - Haddop Configuration에 설정된 디렉터리를 통해 저장
    - 기본 replication은 3개 (각 블록은 서로 다른 3개의 머신에 저장되어 있다는 것을 의미)
  - 네임노드로 불리는 마스터 노드는 어떤 블록들이 파일을 구성하고 있고, 어느 위치에 저장되어 있는지에 대한 정보를 메타데이터로 관리
 

  - hadoop fs -put 명령어: 해당 데이터가 3개의 pc로 분산 자동 저장 - 장애 해결
  
  
 <br/><br/>
 ## MapReduce (데이터 연산)
  - 대용량 데이터 처리를 위한 분산 프로그래밍 모델
  - 구글에서 큰 데이터 분산 병렬처리하기 위한 알고리즘을 보고 아키텍쳐 만듦
  - 분산처리 기술과 관련 프레임워크
  - Data: 분산 DB에 저장됨
  - 처리: 통합 처리 vs 분산 처리
  
  - Map: 흩어져 있는 데이터 key, value 형태로 연관성 있는 데이터 분류로 묶는 작업
  - Reduce: Filtering과 Sorting을 거쳐 데이터 추출, Map화한 작업 중 중복 데이터 제거, 원하는 데이터 추출
  - 셔플링: 처리된 결과를 여러 머신에 이리저리 재배치
  - 맵핑: 데이터를 받아 ㅏ각 데이터 항목을 mapper로 전달, mapper는 입력데이터 필터링하고 reducer가 처리할 수 있는 형태로 변형
  - 리듀싱: mapper로부터 결과값 받아 처리, reducer는 값을 받아 통합
  
  
## NoSQL (Not Only SQL)
- 비관계형 데이터베이스
- Schema-Free: 유연한 데이터 모델
- 분산 다수의 하드웨어에 걸쳐 저장된 데이터
- 용이한 데이터 규모 확장성
- 대용량의 구조적, 반구조적 데이터 다룸 (웹, sns, 그래픽)
- 빅데이터 처리 위한 분산 데이터 저장소 통칭

## Haddop의 구성요소
1. Client: Name Node를 통해 정보를 받고 이후 직접 Data Node와 통신
2. Master Node: 물리적으로 Master Node 역할(Job Tracker, Name Node)을 하는 노드, Slave Node에 대한 정보와 실행을 할 Tasks에 대한 관리
3. Slave node: 물리적 Slave Node 역할(Data Node, Task Node)을 하는 노드, 실제 데이터 분산되어 가지며 Client에서 요청이 오면 데이터를 전달하는 역할 및 담당 Task 수행

- Data Analytics 관점
  - Job Tracker: 노드에 Task를 할당하는 역할과 모든 Task를 모니터링하고 실패할 경우 Task를 재실행하는 역할.
  - Task Tracker: Task는 Map Task와 Reduce Task로 나눠질 수 있으며, Task가 위치한 HDFS의 데이터를 사용하여 MapReduce를 수행.

- Data Storage 관점
  - Name Node: HDFS의 파일 및 디렉터리에 대한 메타 데이터를 유지. 클라이언트로 부터 데이터 위치 요청이 오면 전달, 장애 손상시 Secondary Node로 대체
  - Data Node: 데이터를 HDFS의 Block 단위로 구성. Fault Recovery를 위해 default로 3 copy를 유지, Heartbeat를 통하여 지속적으로 파일 위치 전달.



출처: https://12bme.tistory.com/153 [길은 가면, 뒤에 있다.]
  
  <br/><br/>
 <출처>
 - https://www.youtube.com/channel/UCgJL39Q2O5UTY0B5na1kxHA
 - https://sjh836.tistory.com/43 [빨간색코딩]
 - https://12bme.tistory.com/153
