# 맵리듀스 (MapReduce)
- 구글 발표한 Large Cluster에서의 Data Processing 알고리즘
- 하둡 MapReduce는 소프트웨어 프레임워크로 구현한 구현체
- Key-Value 알고리즘 핵심
  - MapReduce 알고리즘
    - Map Function: (key1, value1) -> (key2, value2)
    - Reduce Function: (key2, List of value2) -> (key3, value3)
    - HDFS 분산 저장 데이터 병렬 처리 취합 역할
    - Job 구동 및 관리는 하둡이 처리 (개발자는 비즈니스 로직 구현 집중)
    
- 장점: 단순, 편리, 특정 데이터 모델이나 스키마나 질의에 의존적이지 않은 유연성, 내구성, 내고장성, 확장성
- 단점: 고정된 단일 데이터 흐름, 불편한 스키마 질의, 단순 스케줄링, 작은 데이터 적합x, 개발도구 불편, 기술지원 어려움

## 맵리듀스 구동 방식
- Local: 단일 JVM에서 전체 Job 실행 (쓰지 않음)
- Classic: Hadoop 0.1 버전까지 MapReduce 분산 처리 방식으로 Job Tracker와 Task Tracker를 사용
- Yarn: 2.0이상 MapReduce 이외에 워크로드 수용 가능

## 주요 컴포넌트
- Client: 구현된 맵리듀스 Job 제출하는 실행 주체 (어플리케이션 실행자)
- JobTracker: 맵리듀스 Job 수행 전체 괴정 조정, Job에 대한 마스터 역할 수행
- TaskTracker: Job에 대한 분할된 Task 수행, 실질적인 Data Processing 주체
- HDFS: 각 단계들 간 데이터와 처리과정에서 발생하는 중간 파일들 공유

### Input Split
- 파일이 여러 개의 블록으로 분할된 블록들을 논리적으로 그룹핑
- Mapper에 정보 전달, 데이터 위치와 읽어들이는 길이 정의

### 구동절차
 <img src="https://github.com/in3166/TIL/blob/main/Hadoop/4.JPG" width="90%">

### 데이터 처리흐름
 <img src="https://github.com/in3166/TIL/blob/main/Hadoop/5.JPG" width="70%">
 
 <br/><br/>
 
## 맵리듀스 구현을 위한 인터페이스
 - 필수 구현 인터페이스는 Mapper 하나
 
 - Input: TextInputFormat(Default) - 읽을 데이터 포맷, 여러 파일 포맷 기본 제공
   - InputFormat: 입력 파일이 분할되는 방식(InputSplit)이나 읽어들이는 방식(RecordReader)을 정의하는 클래스
   - InputFormat은 물리적 Input File을 논리적 InputSplit로 나누고 각각의 InputSplit을 Mapper에  할당
   - SequenceFile: Binary파일, 성능 빠름, mapper의 아웃풋 형태로 주로 사용
   - RecordReader: Mapper가 Format에서 읽은 파일 덩어리를 (128mb를 1mb 버퍼로 계속 전송한다면 1mb 버퍼를 하나의 레코드로) key-value 형태로 반환 후 Mapper에 전달
   
 - Mapper: (k1, v1) -> (k2, v2) - 실제 비지니스 로직 키별 형태로 구현
   - <input -> inputsplit -> recordreader -> map -> inermediate 0/p in Disk>
   
 - Combiner: (k2, list(v2)) -> (k2, v2')
   - 목적: 데이터 전송량 감소
   - Reducer에서 해야하는 연산을 미리 Mapper 쪽에서 물리적으로 연산
    <img src="https://github.com/in3166/TIL/blob/main/Hadoop/6.JPG" width="80%">
    
 - Partitioner: (k2, v2', #reducer) -> #partition 
   - 맵퍼의 결과인 키를 파티셔닝하여 키를 기준으로 서로 다른 노드에서 나온 키들을 같은 키끼리 묶어 같은 서버 전송, output을 Reducer Function을 지난 후 출력
   - 기본 파티셔너는 데이터의 key 값을 해싱 처리하고 Reducer의 개수만큼 모듈러(나머지) 연산하여 같은 것끼리 나눔
       <img src="https://github.com/in3166/TIL/blob/main/Hadoop/7.JPG" width="80%">
   
 - Shuffle-sort: 맵퍼의 아웃풋을 리듀서로 보내는 과정, 데이터를 섞을 후 같은 키를 갖고 있는 것들을 그룹, 정렬 후 리듀서의 인풋으로 보냄
   - 이 과정에서 트래픽량을 최소한으로 프로그래밍해야 성능 상승 -> Combiner와 Partitioner을 사용
   
 - Reducer: (k2, list(v2') -> (k3, v3)
   - 취합(merge) 결과 산출
   - Mapper의 출력 결과를 입력으로 받아 데이터 처리
  
 - Output: TextOutputFormat

## 맵리듀스 Job 진행 상황과 상태 
<img src="https://github.com/in3166/TIL/blob/main/Hadoop/8.JPG" width="60%">

- Task 진행율
  - Map Task: 제출된 Map 개수에 대한 처리 비율
  - Reduce Task: 총 진행을 3단계로 나누어 계산 (셔플 포함)
  
- Counter를 통한 피드백
  - Task는 카운터를 가지며 하둡 프레임워크에 내장되거나 사용자 정의 가능
  - MapReduce 앱 구현 시 원하는 지점에서 카운터를 실행하는 방식으로 이벤트 카운트 가능
  
- 진행 상황의 통지
  - Task는 보고 플래그가 설정되어 있다면 TaskTracker에게 진행 상황 3초마다 보고
  - TaskTracker는 JobTracker에게 HeartBeat를 보낸 떄 진행중인 모든 Task의 상태를 포함하여 전송
  - Client Job은 매초마다 JobTracker를 폴링하여 최신 정보를 갱신

## YARN MapReduce 동작 흐름
<img src="https://github.com/in3166/TIL/blob/main/Hadoop/9.JPG" width="80%">

<출처>

https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=188
